from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.checkpoint.mongodb import MongoDBSaver
from langgraph.graph import START, END, StateGraph
from langgraph.prebuilt import ToolNode
from typing import List, Optional, Dict, Any
import re
from pymongo import MongoClient

from app.config import get_logger
from app.util import SessionManager
from app.model import get_chat_model
from app.tools import get_mood_history, get_recommended_doctors, get_recommended_songs
from .helper import *

logger = get_logger(__name__)

class SimplifiedChatService:
    def __init__(self, mongo_uri: str = "mongodb://mindigo:1234@localhost:27017/", **kwargs):
        """Simplified chat service with efficient routing and minimal API calls."""
        try:
            # MongoDB setup
            self.mongo_client = MongoClient(mongo_uri)
            self.checkpointer = MongoDBSaver(
                client=self.mongo_client,
                db_name="mindigo_checkpoints"
            )
            self.session_manager = SessionManager(self.mongo_client)
            
            # Four-tier model setup for efficient processing
            self.models = {
                "lite": get_chat_model("gemini", model_name="gemini-2.0-flash-lite", **kwargs),      # Fastest, cheapest
                "flash_lite": get_chat_model("gemini", model_name="gemini-2.5-flash-lite", **kwargs), # Quick analysis
                "flash": get_chat_model("gemini", model_name="gemini-2.5-flash", **kwargs),           # Standard processing
                "pro": get_chat_model("gemini", model_name="gemini-2.5-pro", **kwargs)                # Complex analysis
            }
            
            # Customizable tool registry - easy to extend
            self.tool_registry = self._build_tool_registry()
            
            # Crisis patterns for immediate detection
            self.crisis_patterns = self._get_crisis_patterns()
            
            # System message
            self.system_message = get_system_message()
            
            # Build streamlined graph
            self.app = self._build_streamlined_graph()
            
            logger.info("SimplifiedChatService initialized successfully")
        except Exception as e:
            logger.error(f"Initialization error: {str(e)}")
            raise

    def _build_tool_registry(self) -> Dict[str, List]:
        """Build extensible tool registry for easy customization."""
        return {
            "core_tools": [get_recommended_doctors, get_mood_history, get_recommended_songs],
            "wellness_tools": [
                # Add tools like: get_breathing_exercise, get_meditation_guide, get_cbt_worksheet
                # These can be easily added without changing core logic
            ],
            "user_info_tools": [
                # Add tools like: get_user_preferences, get_user_history, get_user_goals
            ],
            "crisis_tools": [
                # Add tools like: get_emergency_contacts, get_crisis_resources
            ]
        }

    def _get_all_tools(self) -> List:
        """Get all available tools from registry."""
        all_tools = []
        for tool_group in self.tool_registry.values():
            all_tools.extend(tool_group)
        return all_tools

    def _get_crisis_patterns(self) -> List[str]:
        """Simple crisis pattern list for quick detection."""
        return [
            'kill myself', 'end my life', 'suicide', 'want to die', 'better off dead',
            'hurt myself', 'self harm', 'cut myself', 'overdose', 'ending it all'
        ]

    def preprocess_text(self, text: str) -> str:
        """Quick text preprocessing - keep it simple and fast."""
        if not text:
            return ""
        
        # Basic cleanup
        text = re.sub(r'\s+', ' ', text.strip())  # Remove extra whitespace
        text = re.sub(r'[!]{3,}', '!!', text)     # Normalize excessive punctuation
        text = re.sub(r'[?]{3,}', '??', text)
        text = re.sub(r'[.]{4,}', '...', text)
        
        # Quick typo fixes for better analysis
        common_fixes = {
            r'\bu\b': 'you', r'\bur\b': 'your', r'\br\b': 'are',
            r'\bidk\b': "I don't know", r'\bomg\b': 'oh my god'
        }
        
        for pattern, replacement in common_fixes.items():
            text = re.sub(pattern, replacement, text, flags=re.IGNORECASE)
        
        return text

    def quick_crisis_check(self, text: str) -> bool:
        """Fast crisis detection for immediate routing."""
        text_lower = text.lower()
        return any(pattern in text_lower for pattern in self.crisis_patterns)

    def _preprocess(self, state: State):
        """Preprocessing node - clean text and add system message."""
        try:
            user_message = state['messages'][-1].content if state['messages'] else ""
            
            # Preprocess the text
            cleaned_text = self.preprocess_text(user_message)
            state['messages'][-1] = HumanMessage(content=cleaned_text)
            
            # Quick crisis check
            has_crisis = self.quick_crisis_check(cleaned_text)
            
            # Add system message if first interaction
            if len(state['messages']) == 1:
                sys_msg = SystemMessage(content=self.system_message)
                return {
                    "messages": [sys_msg] + state['messages'],
                    "has_crisis_indicators": has_crisis,
                    "processed_text": cleaned_text
                }
            
            return {
                "has_crisis_indicators": has_crisis,
                "processed_text": cleaned_text
            }
        except Exception as e:
            logger.error(f"Preprocessing error: {str(e)}")
            return state

    def _initial_analysis(self, state: State):
        """Use lite model for quick initial analysis and routing decision."""
        try:
            # Use the fastest model for initial assessment
            lite_model = self.models["lite"]
            
            analysis_prompt = f"""
            Analyze this message quickly and determine:
            1. Intent: greeting, crisis, question, support_needed, off_topic
            2. Complexity: simple, moderate, complex
            3. Needs_tools: yes/no
            4. Immediate_response_possible: yes/no
            5. Sentiment: positive/neutral/negative
            
            Message: "{state.get('processed_text', '')}"
            
            Respond in JSON format only:
            {{
                "intent": "...",
                "complexity": "...", 
                "needs_tools": "yes/no",
                "immediate_response_possible": "yes/no",
                "sentiment": "...",
                "confidence": 0.8,
                "reasoning": "brief explanation"
            }}
            """
            
            response = lite_model.invoke([HumanMessage(content=analysis_prompt)])
            
            # Parse response (simplified - in production use proper JSON parsing)
            analysis = self._parse_analysis_response(response.content)
            
            return {"initial_analysis": analysis}
            
        except Exception as e:
            logger.error(f"Initial analysis error: {str(e)}")
            # Fallback analysis
            return {
                "initial_analysis": {
                    "intent": "support_needed",
                    "complexity": "moderate",
                    "needs_tools": "no",
                    "immediate_response_possible": "no",
                    "sentiment": "neutral",
                    "confidence": 0.5,
                    "reasoning": "fallback due to error"
                }
            }

    def _parse_analysis_response(self, response: str) -> Dict:
        """Parse the analysis response - simplified JSON extraction."""
        try:
            import json
            # Try to extract JSON from response
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end != 0:
                json_str = response[start:end]
                return json.loads(json_str)
        except:
            pass
        
        # Fallback parsing
        return {
            "intent": "support_needed",
            "complexity": "moderate", 
            "needs_tools": "no",
            "immediate_response_possible": "no",
            "sentiment": "neutral",
            "confidence": 0.5,
            "reasoning": "parsing fallback"
        }

    def _route_by_analysis(self, state: State):
        """Smart routing based on initial analysis."""
        try:
            analysis = state.get("initial_analysis", {})
            has_crisis = state.get("has_crisis_indicators", False)
            
            # Crisis always goes to highest model
            if has_crisis or analysis.get("intent") == "crisis":
                return "crisis_response"
            
            # Simple cases that can be handled immediately
            if (analysis.get("immediate_response_possible") == "yes" and 
                analysis.get("confidence", 0) >= 0.8 and
                analysis.get("needs_tools") == "no"):
                return "direct_response"
            
            # Cases that need tools
            if analysis.get("needs_tools") == "yes":
                return "tool_enhanced_response"
            
            # Complex cases need higher model
            if analysis.get("complexity") == "complex" or analysis.get("confidence", 0) < 0.7:
                return "complex_response"
            
            # Standard processing
            return "standard_response"
            
        except Exception as e:
            logger.error(f"Routing error: {str(e)}")
            return "standard_response"

    def _direct_response(self, state: State):
        """Handle simple cases with flash-lite model - no tools needed."""
        try:
            model = self.models["flash_lite"]
            analysis = state.get("initial_analysis", {})
            
            # Streamlined prompt for direct responses
            if analysis.get("intent") == "greeting":
                prompt = f"Provide a brief, warm greeting response to: {state.get('processed_text')}"
            elif analysis.get("intent") == "off_topic":
                prompt = f"Politely redirect this off-topic message back to mental health support: {state.get('processed_text')}"
            else:
                prompt = f"Provide a brief, supportive response to: {state.get('processed_text')}"
            
            response = model.invoke([HumanMessage(content=prompt)])
            return {"messages": state["messages"] + [response]}
            
        except Exception as e:
            logger.error(f"Direct response error: {str(e)}")
            return state

    def _tool_enhanced_response(self, state: State):
        """Handle cases that need tools - use flash model with bound tools."""
        try:
            # Use bind_tools approach for better control
            model = self.models["flash"]
            tools = self._get_all_tools()
            model_with_tools = model.bind_tools(tools)
            
            response = model_with_tools.invoke(state["messages"])
            return {"messages": state["messages"] + [response]}
            
        except Exception as e:
            logger.error(f"Tool enhanced response error: {str(e)}")
            return state

    def _standard_response(self, state: State):
        """Standard processing with flash model - no tools by default."""
        try:
            model = self.models["flash"]
            response = model.invoke(state["messages"])
            return {"messages": state["messages"] + [response]}
            
        except Exception as e:
            logger.error(f"Standard response error: {str(e)}")
            return state

    def _complex_response(self, state: State):
        """Complex processing with pro model and tools."""
        try:
            model = self.models["pro"]
            tools = self._get_all_tools()
            model_with_tools = model.bind_tools(tools)
            
            response = model_with_tools.invoke(state["messages"])
            return {"messages": state["messages"] + [response]}
            
        except Exception as e:
            logger.error(f"Complex response error: {str(e)}")
            return state

    def _crisis_response(self, state: State):
        """Crisis handling with pro model and immediate response."""
        try:
            model = self.models["pro"]
            user_name = state.get('user_name', 'there')
            
            crisis_prompt = f"""
            CRISIS SITUATION DETECTED
            
            User: {user_name}
            Message: {state.get('processed_text', '')}
            
            Provide immediate crisis support including:
            1. Validation and concern
            2. Crisis hotlines (988, 911, text 741741)
            3. Encourage immediate professional help
            4. Warm but directive tone
            
            Keep response focused and actionable.
            """
            
            response = model.invoke([HumanMessage(content=crisis_prompt)])
            return {"messages": state["messages"] + [response]}
            
        except Exception as e:
            logger.error(f"Crisis response error: {str(e)}")
            # Fallback crisis response
            fallback_msg = get_crisis_response(state.get('user_name', 'there'))
            return {"messages": state["messages"] + [AIMessage(content=fallback_msg)]}

    def _route_to_tools(self, state: State):
        """Check if tools are needed after response."""
        try:
            last_msg = state["messages"][-1]
            
            # If tools were called, process them
            if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
                return "tools"
            
            # Otherwise go to final processing
            return "final_processing"
            
        except Exception as e:
            logger.error(f"Tool routing error: {str(e)}")
            return "final_processing"

    def _final_processing(self, state: State):
        """Final safety check and response formatting."""
        try:
            user_message = state.get('processed_text', '')
            has_crisis = state.get('has_crisis_indicators', False)
            analysis = state.get('initial_analysis', {})
            
            # Safety assessment
            safety_level = "crisis" if has_crisis else "none"
            if analysis.get("sentiment") == "negative" and "hopeless" in user_message.lower():
                safety_level = "concern"
            
            safety_alert = SafetyAlert(
                level=safety_level,
                triggers=["crisis_pattern"] if has_crisis else [],
                immediate_action_required=has_crisis
            )
            
            # Update safety score
            current_score = state.get("safety_score", 0)
            new_score = min(current_score + (2 if has_crisis else 0), 5)
            
            # Use appropriate model for structured response
            model_choice = "pro" if has_crisis else "flash"
            model = self.models[model_choice]
            structured_model = model.with_structured_output(Response)
            
            # Create complexity info
            complexity = TaskComplexity(
                level=analysis.get("complexity", "moderate"),
                reasoning=analysis.get("reasoning", "standard processing"),
                use_tools=analysis.get("needs_tools") == "yes",
                requires_history=False
            )
            
            prompt = get_final_prompt(state, complexity, safety_alert)
            output: Response = structured_model.invoke(prompt)
            
            # Set safety information
            output.safety_alert = safety_alert
            output.escalate = has_crisis
            
            final_msg = AIMessage(
                content=output.message,
                additional_kwargs={"structured": output.dict()}
            )
            
            return {
                "messages": state["messages"] + [final_msg],
                "safety_score": new_score,
                "safety_alert": safety_alert
            }
            
        except Exception as e:
            logger.error(f"Final processing error: {str(e)}")
            # Fallback response
            fallback_response = Response(
                message=f"Hi {state.get('user_name', 'there')}, I'm here to support you. How are you feeling?",
                escalate=has_crisis
            )
            
            final_msg = AIMessage(
                content=fallback_response.message,
                additional_kwargs={"structured": fallback_response.dict()}
            )
            
            return {"messages": state["messages"] + [final_msg]}

    def _build_streamlined_graph(self):
        """Build efficient workflow graph with minimal nodes."""
        try:
            workflow = StateGraph(state_schema=State)
            
            # Core processing nodes
            workflow.add_node("preprocess", self._preprocess)
            workflow.add_node("initial_analysis", self._initial_analysis)
            workflow.add_node("direct_response", self._direct_response)
            workflow.add_node("standard_response", self._standard_response)
            workflow.add_node("tool_enhanced_response", self._tool_enhanced_response)
            workflow.add_node("complex_response", self._complex_response)
            workflow.add_node("crisis_response", self._crisis_response)
            workflow.add_node("tools", ToolNode(self._get_all_tools()))
            workflow.add_node("final_processing", self._final_processing)
            
            # Build efficient workflow
            workflow.add_edge(START, "preprocess")
            workflow.add_edge("preprocess", "initial_analysis")
            
            # Smart routing based on analysis
            workflow.add_conditional_edges(
                "initial_analysis",
                self._route_by_analysis,
                {
                    "direct_response": "direct_response",
                    "standard_response": "standard_response",
                    "tool_enhanced_response": "tool_enhanced_response",
                    "complex_response": "complex_response",
                    "crisis_response": "crisis_response"
                }
            )
            
            # All response nodes can potentially use tools
            for response_node in ["direct_response", "standard_response", "tool_enhanced_response", 
                                "complex_response", "crisis_response"]:
                workflow.add_conditional_edges(
                    response_node,
                    self._route_to_tools,
                    {"tools": "tools", "final_processing": "final_processing"}
                )
            
            workflow.add_edge("tools", "final_processing")
            workflow.add_edge("final_processing", END)
            
            return workflow.compile(checkpointer=self.checkpointer)
            
        except Exception as e:
            logger.error(f"Graph building error: {str(e)}")
            raise

    # Public API methods
    def chat(self, message: str, user_id: int, user_name: str, session_id: str = None) -> Dict[str, Any]:
        """Efficient chat interface with minimal API calls."""
        try:
            # Session management
            final_session_id = self.session_manager.get_or_create_session(
                user_id, user_name, session_id
            )
            
            config = {"configurable": {"thread_id": final_session_id}}
            
            # Get session data
            session_data = self.session_manager.get_session(final_session_id)
            initial_safety_score = session_data.get('safety_score', 0) if session_data else 0
            
            # Create initial state
            initial_state = {
                "messages": [HumanMessage(content=message)],
                "user_id": user_id,
                "user_name": user_name,
                "session_id": final_session_id,
                "safety_score": initial_safety_score
            }
            
            # Process through streamlined workflow
            final_state = self.app.invoke(initial_state, config)
            
            # Extract results
            last_message = final_state["messages"][-1]
            structured_data = last_message.additional_kwargs.get("structured", {})
            
            # Log safety alerts
            safety_alert = structured_data.get("safety_alert", {})
            if safety_alert.get("level") in ["warning", "crisis"]:
                logger.warning(f"SAFETY ALERT for user {user_id}: {safety_alert}")
            
            # Update session
            self.session_manager.update_session(final_session_id, {
                'safety_score': final_state.get('safety_score', initial_safety_score),
                'last_message': message,
                'last_response': last_message.content
            })
            
            return {
                "message": last_message.content,
                "mood": structured_data.get("mood"),
                "recommendations": structured_data.get("recommendations", []),
                "escalate": structured_data.get("escalate", False),
                "safety_alert": safety_alert,
                "session_id": final_session_id,
                "analysis": final_state.get("initial_analysis")  # Include analysis for debugging
            }
            
        except Exception as e:
            logger.error(f"Chat error: {str(e)}")
            return {
                "message": "I'm here to support you. How are you feeling?",
                "mood": None,
                "recommendations": [],
                "escalate": False,
                "safety_alert": {},
                "session_id": session_id,
                "analysis": None
            }

    def add_tools(self, tool_category: str, tools: List):
        """Add tools to specific category for easy customization."""
        if tool_category not in self.tool_registry:
            self.tool_registry[tool_category] = []
        self.tool_registry[tool_category].extend(tools)
        
        # Rebuild the workflow with new tools
        self.app = self._build_streamlined_graph()
        logger.info(f"Added {len(tools)} tools to category: {tool_category}")

    def get_session(self, session_id: str) -> Optional[Dict]:
        """Get session information."""
        return self.session_manager.get_session(session_id)

    def close(self):
        """Close connections."""
        try:
            if hasattr(self, 'mongo_client'):
                self.mongo_client.close()
        except Exception as e:
            logger.error(f"Error closing connections: {str(e)}")


# Usage example for tool customization
def example_tool_customization():
    """Example of how to add custom tools"""
    
    # Initialize service
    service = SimplifiedChatService()
    
    # Example: Add breathing exercise tool
    def get_breathing_exercise():
        """Custom breathing exercise tool"""
        return {
            "type": "activity",
            "title": "4-7-8 Breathing Exercise", 
            "instructions": [
                "Inhale for 4 counts",
                "Hold for 7 counts", 
                "Exhale for 8 counts",
                "Repeat 4 times"
            ],
            "duration": "2 minutes"
        }
    
    # Example: Add user preference tool
    def get_user_preferences(user_id: int):
        """Get user preferences"""
        # This would fetch from database
        return {
            "preferred_coping_strategies": ["breathing", "music"],
            "trigger_words": ["work", "family"],
            "communication_style": "gentle"
        }
    
    # Add tools to service
    service.add_tools("wellness_tools", [get_breathing_exercise])
    service.add_tools("user_info_tools", [get_user_preferences])
    
    return service


if __name__ == "__main__":
    # Quick test
    service = SimplifiedChatService()
    
    test_messages = [
        "Hi there!",  # Should use direct_response with flash-lite
        "I'm feeling anxious",  # Should use standard_response with flash
        "I need a therapist",  # Should use tool_enhanced_response with flash + tools
        "I want to hurt myself",  # Should use crisis_response with pro
    ]
    
    for msg in test_messages:
        print(f"\nTesting: '{msg}'")
        result = service.chat(msg, 123, "TestUser")
        print(f"Response: {result['message'][:100]}...")
        print(f"Analysis: {result.get('analysis')}")
        print(f"Safety: {result.get('safety_alert', {}).get('level', 'none')}")
