from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langgraph.checkpoint.mongodb import MongoDBSaver
from langgraph.graph import START, END, StateGraph
from langgraph.prebuilt import ToolNode
from typing import List, Optional, Dict, Any
import re
from datetime import datetime
from pymongo import MongoClient

from app.config import get_logger
from app.util import SessionManager
from app.model import get_chat_model
from app.tools import get_mood_history, get_recommended_doctors, get_recommended_songs
from .helper import *

logger = get_logger(__name__)

class EnhancedChatService:
    """Enhanced mental health chat service with improved safety and scalability"""
    
    def __init__(self, mongo_uri: str = "mongodb://mindigo:1234@localhost:27017/", **kwargs):
        try:
            # Core setup
            self.mongo_client = MongoClient(mongo_uri)
            self.checkpointer = MongoDBSaver(
                client=self.mongo_client,
                db_name="mindigo_checkpoints"
            )
            self.session_manager = SessionManager(self.mongo_client)
            
            # Models for different complexity levels
            self.models = self._get_models(**kwargs)
            
            # Specialized models
            self.intent_classifier = get_chat_model("gemini", model_name="gemini-1.5-flash", **kwargs)
            self.safety_classifier = get_chat_model("gemini", model_name="gemini-1.5-flash", **kwargs)
            
            # Tool registry for easy extension
            self.tool_registry = self._build_tool_registry()
            
            # Crisis detection system
            self.crisis_keywords = self._get_crisis_keywords()
            
            # System messages
            self.system_message = get_system_message()
            
            # Build enhanced graph
            self.app = self._build_enhanced_graph()
            
            logger.info("EnhancedChatService initialized successfully")
        except Exception as e:
            logger.error(f"Initialization error: {str(e)}")
            raise

    def _get_models(self, **kwargs) -> Dict[str, Any]:
        """Get configurable models for different complexity levels"""
        return {
            "simple": get_chat_model("gemini", model_name="gemini-1.5-flash", **kwargs),
            "moderate": get_chat_model("gemini", model_name="gemini-2.0-flash", **kwargs), 
            "complex": get_chat_model("gemini", model_name="gemini-2.0-flash", **kwargs),
            "crisis": get_chat_model("gemini", model_name="gemini-2.0-flash", **kwargs)
        }

    def _build_tool_registry(self) -> Dict[str, Dict]:
        """Build extensible tool registry"""
        return {
            "core_tools": {
                "get_mood_history": get_mood_history,
                "get_recommended_doctors": get_recommended_doctors,
                "get_recommended_songs": get_recommended_songs
            },
            "therapeutic_tools": {
                # Future tools can be added here
                # "guided_meditation": guided_meditation_tool,
                # "breathing_exercise": breathing_exercise_tool,
                # "cbt_worksheet": cbt_worksheet_tool,
                # "mood_journal": mood_journal_tool
            },
            "crisis_tools": {
                # Emergency contact tools, crisis resources
                # "emergency_contacts": emergency_contacts_tool,
                # "crisis_resources": crisis_resources_tool
            }
        }

    def _get_crisis_keywords(self) -> Dict[str, List[str]]:
        """Enhanced crisis keywords with subtle indicators"""
        return {
            'explicit_suicide': ['suicide', 'kill myself', 'end my life', 'want to die', 'better off dead'],
            'subtle_suicide': ['tired of living', 'nothing matters', 'permanent solution', 'everyone would be better without me'],
            'self_harm': ['cut myself', 'hurt myself', 'self harm', 'pain helps', 'deserve pain'],
            'violence': ['hurt others', 'kill them', 'make them pay', 'they deserve to die'],
            'severe_crisis': ['ending it all', 'final solution', 'goodbye forever', 'last time', 'cant go on'],
            'substance_abuse': ['overdose', 'too many pills', 'drinking to forget', 'numbing the pain'],
            'hopelessness': ['no point', 'hopeless', 'nothing will change', 'stuck forever']
        }

    # NEW NODE: Preprocessing
    def _preprocess(self, state: State):
        """Preprocess incoming messages for length, content, and basic safety"""
        try:
            user_message = state['messages'][-1].content if state['messages'] else ""
            
            # Handle extremely long messages
            if len(user_message) > 2000:
                chunks = self._chunk_message(user_message)
                # Focus on the most emotionally significant chunk
                user_message = self._select_primary_chunk(chunks)
                state['messages'][-1] = HumanMessage(content=user_message)
            
            # Basic content filtering
            processed_message = self._clean_message(user_message)
            state['messages'][-1] = HumanMessage(content=processed_message)
            
            # Early crisis detection flag
            has_crisis_indicators = self._has_crisis_indicators(processed_message)
            
            return {
                "messages": state["messages"],
                "preprocessing_flags": {
                    "long_message": len(user_message) > 500,
                    "possible_crisis": has_crisis_indicators
                }
            }
        except Exception as e:
            logger.error(f"Error in preprocessing: {str(e)}")
            return state

    def _chunk_message(self, message: str, chunk_size: int = 500) -> List[str]:
        """Break long messages into meaningful chunks"""
        sentences = re.split(r'[.!?]+', message)
        chunks = []
        current_chunk = ""
        
        for sentence in sentences:
            if len(current_chunk + sentence) < chunk_size:
                current_chunk += sentence + ". "
            else:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = sentence + ". "
        
        if current_chunk:
            chunks.append(current_chunk.strip())
        
        return chunks

    def _select_primary_chunk(self, chunks: List[str]) -> str:
        """Select the most emotionally significant chunk"""
        emotional_keywords = [
            'feel', 'sad', 'depressed', 'anxious', 'scared', 'angry', 
            'hopeless', 'worried', 'stressed', 'overwhelmed', 'crisis'
        ]
        
        chunk_scores = []
        for chunk in chunks:
            score = sum(1 for keyword in emotional_keywords if keyword in chunk.lower())
            chunk_scores.append((score, chunk))
        
        # Return chunk with highest emotional content
        return max(chunk_scores, key=lambda x: x[0])[1] if chunk_scores else chunks[0]

    def _clean_message(self, message: str) -> str:
        """Basic message cleaning"""
        # Remove excessive whitespace
        message = re.sub(r'\s+', ' ', message).strip()
        # Handle basic typos that might affect crisis detection
        # Add any other necessary cleaning
        return message

    def _has_crisis_indicators(self, message: str) -> bool:
        """Quick crisis indicator check for early flagging"""
        message_lower = message.lower()
        return any(
            keyword in message_lower 
            for keywords in self.crisis_keywords.values() 
            for keyword in keywords
        )

    # NEW NODE: Intent Classification
    def _classify_intent(self, state: State):
        """Classify user intent and safety level"""
        try:
            user_message = state['messages'][-1].content
            preprocessing_flags = state.get('preprocessing_flags', {})
            
            # Enhanced intent classification prompt
            intent_prompt = f"""
            Analyze this mental health support message and classify:
            
            Message: "{user_message}"
            
            Classify the following:
            1. Intent: greeting, crisis, support_seeking, information, tools_needed, unclear
            2. Emotional_state: calm, mild_distress, moderate_distress, severe_distress, crisis
            3. Urgency: low, medium, high, immediate
            4. Clarity: clear, somewhat_unclear, very_unclear
            
            Output as JSON:
            {{
                "intent": "...",
                "emotional_state": "...", 
                "urgency": "...",
                "clarity": "...",
                "needs_clarification": boolean,
                "tools_suggested": ["tool1", "tool2"],
                "reasoning": "brief explanation"
            }}
            """
            
            response = self.intent_classifier.invoke([HumanMessage(content=intent_prompt)])
            
            # Parse the response (implement proper JSON parsing)
            intent_data = self._parse_intent_response(response.content)
            
            return {
                "intent_classification": intent_data,
                "preprocessing_flags": preprocessing_flags
            }
        except Exception as e:
            logger.error(f"Error in intent classification: {str(e)}")
            # Fallback classification
            return {
                "intent_classification": {
                    "intent": "support_seeking",
                    "emotional_state": "moderate_distress",
                    "urgency": "medium",
                    "clarity": "clear",
                    "needs_clarification": False,
                    "tools_suggested": [],
                    "reasoning": "fallback classification"
                }
            }

    def _parse_intent_response(self, response: str) -> Dict:
        """Parse intent classification response"""
        # Implement proper JSON parsing with fallbacks
        # This is a simplified version
        try:
            import json
            return json.loads(response)
        except:
            return {
                "intent": "support_seeking",
                "emotional_state": "moderate_distress", 
                "urgency": "medium",
                "clarity": "clear",
                "needs_clarification": False,
                "tools_suggested": [],
                "reasoning": "parsing error fallback"
            }

    # NEW NODE: Clarification
    def _clarification(self, state: State):
        """Handle unclear or ambiguous requests"""
        try:
            user_name = state.get('user_name', 'there')
            
            clarifying_questions = [
                f"Hi {user_name}, I want to make sure I understand how best to support you. Could you tell me a bit more about what you're experiencing?",
                f"I'm here to listen, {user_name}. What's been on your mind lately?",
                f"Thank you for reaching out, {user_name}. Can you share what's prompting you to seek support today?"
            ]
            
            # Select appropriate clarifying question based on context
            question = clarifying_questions[0]  # Simple selection for now
            
            response = AIMessage(content=question)
            return {"messages": state["messages"] + [response]}
        except Exception as e:
            logger.error(f"Error in clarification: {str(e)}")
            return state

    # ENHANCED NODE: Advanced Safety Check
    def _advanced_safety_check(self, state: State):
        """Enhanced safety assessment with ML and pattern analysis"""
        try:
            user_message = state['messages'][-1].content if state['messages'] else ""
            session_id = state.get('session_id')
            
            # Get conversation history for pattern analysis
            conversation_history = self._get_recent_conversation_history(session_id, limit=10)
            
            # Multi-layered safety assessment
            safety_scores = {
                'keyword_score': self._keyword_safety_score(user_message),
                'pattern_score': self._pattern_safety_score(conversation_history),
                'ml_score': self._ml_safety_score(user_message),
                'context_score': self._context_safety_score(state)
            }
            
            # Aggregate safety assessment
            overall_safety = self._aggregate_safety_scores(safety_scores)
            
            # Enhanced crisis detection
            safety_alert = self._create_enhanced_safety_alert(user_message, overall_safety, state)
            
            # Update safety score with more nuanced calculation
            new_safety_score = self._calculate_safety_score(state.get('safety_score', 0), overall_safety)
            
            # Log detailed safety information
            if overall_safety['level'] in ['warning', 'crisis']:
                logger.warning(f"Safety concern for user {state.get('user_id')}: {overall_safety}")
            
            return {
                "safety_assessment": overall_safety,
                "safety_alert": safety_alert,
                "safety_score": new_safety_score
            }
        except Exception as e:
            logger.error(f"Error in advanced safety check: {str(e)}")
            return state

    def _keyword_safety_score(self, message: str) -> Dict:
        """Enhanced keyword-based safety scoring"""
        message_lower = message.lower()
        scores = {}
        
        for category, keywords in self.crisis_keywords.items():
            score = sum(1 for keyword in keywords if keyword in message_lower)
            scores[category] = score
        
        return scores

    def _pattern_safety_score(self, history: List[str]) -> Dict:
        """Analyze conversation patterns for safety risks"""
        if not history:
            return {'deterioration': 0, 'consistency': 0}
        
        # Look for deteriorating mood patterns
        negative_keywords = ['worse', 'hopeless', 'giving up', 'pointless', 'tired']
        deterioration_score = 0
        
        for i, message in enumerate(history):
            message_lower = message.lower()
            negative_count = sum(1 for keyword in negative_keywords if keyword in message_lower)
            # Weight recent messages more heavily
            weight = (i + 1) / len(history)
            deterioration_score += negative_count * weight
        
        return {
            'deterioration': min(deterioration_score, 5),
            'consistency': len(history)
        }

    def _ml_safety_score(self, message: str) -> Dict:
        """ML-based safety scoring (placeholder for actual ML model)"""
        # In production, this would call a trained suicide risk assessment model
        # For now, return a placeholder score based on message characteristics
        
        risk_indicators = {
            'length_concern': 1 if len(message) < 20 and any(word in message.lower() for word in ['done', 'over', 'end']) else 0,
            'time_references': 1 if any(word in message.lower() for word in ['tonight', 'today', 'now', 'soon']) else 0,
            'finality': 1 if any(word in message.lower() for word in ['final', 'last', 'goodbye', 'forever']) else 0
        }
        
        return risk_indicators

    def _context_safety_score(self, state: State) -> Dict:
        """Consider contextual factors for safety assessment"""
        context_factors = {
            'time_of_day': self._assess_time_risk(),
            'session_frequency': self._assess_session_frequency(state),
            'safety_history': state.get('safety_score', 0)
        }
        
        return context_factors

    def _assess_time_risk(self) -> int:
        """Assess risk based on time of day"""
        hour = datetime.now().hour
        # Higher risk during late night/early morning hours
        if 0 <= hour <= 6 or 22 <= hour <= 23:
            return 2
        elif 6 < hour <= 10 or 18 <= hour < 22:
            return 1
        return 0

    def _assess_session_frequency(self, state: State) -> int:
        """Assess risk based on session patterns"""
        # In a real implementation, analyze session frequency from database
        return 0

    def _aggregate_safety_scores(self, scores: Dict) -> Dict:
        """Aggregate multiple safety scores into overall assessment"""
        keyword_total = sum(scores['keyword_score'].values())
        pattern_risk = scores['pattern_score']['deterioration']
        ml_risk = sum(scores['ml_score'].values())
        context_risk = sum(scores['context_score'].values())
        
        total_score = keyword_total + pattern_risk + ml_risk + context_risk
        
        if total_score >= 5 or keyword_total >= 3:
            level = "crisis"
        elif total_score >= 3 or keyword_total >= 2:
            level = "warning"
        elif total_score >= 1:
            level = "concern"
        else:
            level = "none"
        
        return {
            'level': level,
            'total_score': total_score,
            'breakdown': scores,
            'reasoning': f"Total risk score: {total_score}"
        }

    def _create_enhanced_safety_alert(self, message: str, safety_assessment: Dict, state: State) -> SafetyAlert:
        """Create enhanced safety alert with detailed information"""
        level = safety_assessment['level']
        triggers = []
        
        # Extract specific triggers
        for category, keywords in self.crisis_keywords.items():
            if any(keyword in message.lower() for keyword in keywords):
                triggers.append(category)
        
        immediate_action = level == "crisis"
        emergency_msg = None
        
        if immediate_action:
            emergency_msg = get_crisis_response(state.get('user_name', 'there'))
        
        return SafetyAlert(
            level=level,
            triggers=triggers,
            immediate_action_required=immediate_action,
            emergency_message=emergency_msg
        )

    def _calculate_safety_score(self, current_score: int, safety_assessment: Dict) -> int:
        """Calculate updated safety score"""
        level = safety_assessment['level']
        
        if level == "crisis":
            return min(current_score + 2, 5)
        elif level == "warning":
            return min(current_score + 1, 5)
        elif level == "concern":
            return max(current_score, 1)
        else:
            return max(current_score - 1, 0)

    def _get_recent_conversation_history(self, session_id: str, limit: int = 10) -> List[str]:
        """Get recent conversation history for pattern analysis"""
        try:
            # In a real implementation, query the database for recent messages
            # This is a placeholder
            return []
        except Exception as e:
            logger.error(f"Error getting conversation history: {str(e)}")
            return []

    # ENHANCED ROUTING LOGIC
    def _route_by_intent(self, state: State):
        """Enhanced routing based on intent classification"""
        try:
            intent_data = state.get('intent_classification', {})
            preprocessing_flags = state.get('preprocessing_flags', {})
            
            intent = intent_data.get('intent', 'support_seeking')
            clarity = intent_data.get('clarity', 'clear')
            urgency = intent_data.get('urgency', 'medium')
            
            # Crisis always gets immediate attention
            if preprocessing_flags.get('possible_crisis') or urgency == 'immediate':
                return "crisis_response"
            
            # Unclear requests need clarification
            if clarity == 'very_unclear' or intent_data.get('needs_clarification', False):
                return "clarification"
            
            # Route based on intent and complexity
            if intent == 'greeting':
                return "simple_chat"
            elif intent == 'tools_needed':
                return "complex_chat"
            elif urgency == 'high':
                return "complex_chat"
            else:
                return "moderate_chat"
                
        except Exception as e:
            logger.error(f"Error in intent routing: {str(e)}")
            return "moderate_chat"

    # NEW NODE: Crisis Response
    def _crisis_response(self, state: State):
        """Specialized crisis response handling"""
        try:
            model = self.models["crisis"]
            user_name = state.get('user_name', 'there')
            
            crisis_prompt = f"""
            CRISIS RESPONSE PROTOCOL
            
            User: {user_name}
            Message: {state['messages'][-1].content}
            
            This is a potential crisis situation. Provide:
            1. Immediate validation and concern
            2. Crisis resources and hotlines
            3. Encourage immediate professional help
            4. Warm, supportive tone while being directive
            
            Include:
            - 988 Suicide & Crisis Lifeline
            - Local emergency services (911)
            - Crisis text line (741741)
            
            Keep response concise but comprehensive.
            """
            
            response = model.invoke([HumanMessage(content=crisis_prompt)])
            return {"messages": state["messages"] + [response]}
            
        except Exception as e:
            logger.error(f"Error in crisis response: {str(e)}")
            # Fallback crisis response
            fallback_msg = get_crisis_response(state.get('user_name', 'there'))
            return {"messages": state["messages"] + [AIMessage(content=fallback_msg)]}

    # ENHANCED GRAPH BUILDER
    def _build_enhanced_graph(self):
        """Build the enhanced workflow graph"""
        try:
            workflow = StateGraph(state_schema=State)
            
            # Add all nodes
            workflow.add_node("preprocess", self._preprocess)
            workflow.add_node("classify_intent", self._classify_intent)
            workflow.add_node("clarification", self._clarification)
            workflow.add_node("simple_chat", self._simple_chat)
            workflow.add_node("moderate_chat", self._moderate_chat)
            workflow.add_node("complex_chat", self._complex_chat)
            workflow.add_node("crisis_response", self._crisis_response)
            workflow.add_node("tools", ToolNode(list(self.tool_registry["core_tools"].values())))
            workflow.add_node("advanced_safety_check", self._advanced_safety_check)
            workflow.add_node("respond", self._respond)
            
            # Build enhanced workflow
            workflow.add_edge(START, "preprocess")
            workflow.add_edge("preprocess", "classify_intent")
            
            # Route based on intent classification
            workflow.add_conditional_edges(
                "classify_intent",
                self._route_by_intent,
                {
                    "clarification": "clarification",
                    "simple_chat": "simple_chat",
                    "moderate_chat": "moderate_chat",
                    "complex_chat": "complex_chat",
                    "crisis_response": "crisis_response"
                }
            )
            
            # All chat nodes route to safety check
            for node in ["simple_chat", "moderate_chat", "complex_chat", "crisis_response", "clarification"]:
                workflow.add_conditional_edges(
                    node,
                    self._route_after_chat,
                    {"tools": "tools", "safety_check": "advanced_safety_check"}
                )
            
            workflow.add_edge("tools", "advanced_safety_check")
            workflow.add_edge("advanced_safety_check", "respond")
            workflow.add_edge("respond", END)
            
            return workflow.compile(checkpointer=self.checkpointer)
            
        except Exception as e:
            logger.error(f"Error building enhanced graph: {str(e)}")
            raise

    # Existing methods (simplified for brevity)
    def _simple_chat(self, state: State):
        """Handle simple messages with lightweight processing"""
        try:
            model = self.models["simple"]
            recent_messages = state["messages"][-3:] if len(state["messages"]) > 3 else state["messages"]
            response = model.invoke(recent_messages)
            return {"messages": state["messages"] + [response]}
        except Exception as e:
            logger.error(f"Error in simple_chat: {str(e)}")
            return state

    def _moderate_chat(self, state: State):
        """Handle moderate complexity messages"""
        try:
            model = self.models["moderate"]
            response = model.invoke(state["messages"])
            return {"messages": state["messages"] + [response]}
        except Exception as e:
            logger.error(f"Error in moderate_chat: {str(e)}")
            return state

    def _complex_chat(self, state: State):
        """Handle complex messages that may need tools"""
        try:
            model = self.models["complex"]
            tools = list(self.tool_registry["core_tools"].values())
            model_with_tools = model.bind_tools(tools)
            response = model_with_tools.invoke(state["messages"])
            return {"messages": state["messages"] + [response]}
        except Exception as e:
            logger.error(f"Error in complex_chat: {str(e)}")
            return state

    def _route_after_chat(self, state: State):
        """Route after initial chat response"""
        try:
            last_msg = state["messages"][-1]
            if hasattr(last_msg, 'tool_calls') and last_msg.tool_calls:
                return "tools"
            return "safety_check"
        except Exception as e:
            logger.error(f"Error in route_after_chat: {str(e)}")
            return "safety_check"

    def _respond(self, state: State):
        """Generate final structured response with enhanced safety information"""
        try:
            complexity = state.get("task_complexity", TaskComplexity(level="moderate", reasoning="default"))
            model = self.models[complexity.level]
            structured_model = model.with_structured_output(Response)
            
            safety_alert = state.get("safety_alert", SafetyAlert(level="none"))
            safety_assessment = state.get("safety_assessment", {})
            
            logger.info(f"Generating response with safety level: {safety_alert.level}")
            
            prompt = get_final_prompt(state, complexity, safety_alert)
            output: Response = structured_model.invoke(prompt)
            
            # Enhance output with safety information
            output.safety_alert = safety_alert
            output.escalate = safety_alert.immediate_action_required
            
            final_msg = AIMessage(
                content=output.message,
                additional_kwargs={
                    "structured": output.dict(),
                    "safety_assessment": safety_assessment
                }
            )
            return {"messages": state["messages"] + [final_msg]}
            
        except Exception as e:
            logger.error(f"Error in respond node: {str(e)}")
            # Enhanced fallback with safety consideration
            safety_alert = state.get("safety_alert", SafetyAlert(level="none"))
            
            if safety_alert.level == "crisis":
                fallback_message = get_crisis_response(state.get('user_name', 'there'))
            else:
                fallback_message = f"Hi {state.get('user_name', 'there')}, I'm here to listen and support you. How are you feeling right now?"
            
            fallback_response = Response(
                message=fallback_message,
                safety_alert=safety_alert,
                escalate=safety_alert.immediate_action_required
            )
            
            final_msg = AIMessage(
                content=fallback_response.message,
                additional_kwargs={"structured": fallback_response.dict()}
            )
            return {"messages": state["messages"] + [final_msg]}

    # API Methods
    def chat(self, message: str, user_id: int, user_name: str, session_id: str = None) -> Dict[str, Any]:
        """Enhanced chat interface with improved error handling"""
        try:
            final_session_id = self.session_manager.get_or_create_session(
                user_id, user_name, session_id
            )
            
            config = {"configurable": {"thread_id": final_session_id}}
            
            session_data = self.session_manager.get_session(final_session_id)
            initial_safety_score = session_data.get('safety_score', 0) if session_data else 0
            
            initial_state = {
                "messages": [HumanMessage(content=message)],
                "user_id": user_id,
                "user_name": user_name,
                "session_id": final_session_id,
                "safety_score": initial_safety_score
            }
            
            final_state = self.app.invoke(initial_state, config)
            
            # Extract enhanced response data
            last_message = final_state["messages"][-1]
            structured_data = last_message.additional_kwargs.get("structured", {})
            safety_assessment = last_message.additional_kwargs.get("safety_assessment", {})
            
            # Enhanced logging for safety incidents
            safety_alert = structured_data.get("safety_alert", {})
            if safety_alert.get("level") in ["warning", "crisis"]:
                logger.warning(f"Safety incident - User: {user_id}, Level: {safety_alert.get('level')}, Session: {final_session_id}")
            
            # Update session with comprehensive data
            self.session_manager.update_session(final_session_id, {
                'safety_score': final_state.get('safety_score', initial_safety_score),
                'last_message': message,
                'last_response': last_message.content,
                'last_safety_level': safety_alert.get("level", "none"),
                'safety_assessment': safety_assessment
            })
            
            return {
                "message": last_message.content,
                "session_id": final_session_id,
                "safety_assessment": safety_assessment,
                **structured_data
            }
            
        except Exception as e:
            logger.error(f"Chat error for user {user_id}: {str(e)}")
            return {
                "message": "I apologize, but I'm having trouble right now. If you're in crisis, please call 988 or emergency services immediately.",
                "error": True,
                "escalate": True
            }

    def close(self):
        """Close database connections"""
        try:
            if hasattr(self, 'mongo_client'):
                self.mongo_client.close()
        except Exception as e:
            logger.error(f"Error closing connections: {str(e)}")
